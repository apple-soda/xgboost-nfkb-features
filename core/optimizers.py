import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from tqdm import tqdm

from core.dataset import *
from core.dprocessing import *
from core.utils import *

def optimize_features(features, time_steps, feature_list, dataset, initial_bound, interval, display=True):
    """
    Parameters:
    * feature_list: list of lists generated by df.values.to_list() function
    * interval: the number of sections to divide the feature list into for testing
    """
    ligands = ['CpG', 'FLA', 'FSL', 'LPS', 'P3K', 'PIC', 'R84', 'TNF']
    feature_list = feature_list[:int(len(feature_list) * initial_bound)]
    labels = dataset.iloc[:, [dataset.shape[1] - 1]] # last column of dataset = corresponding class labels
    labels = labels.to_numpy()
    labels = labels.reshape((-1, ))
    
    for i in tqdm(range(interval, 0, -1)):
        x = i / interval
        pfl = feature_list[:int(len(feature_list) * x)]
        data = partition_features(features, time_steps, pfl, 1, dataset) # bound = 1 because we already split the feature_list
        data = data.to_numpy()
        X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.1)
        model = xgb.XGBClassifier(use_label_encoder=False) # ignore deprecation warning
        model.fit(X_train, y_train)
        pred = model.predict(X_val)
        cr = classification_report(y_val, pred, target_names=ligands)
        
        if display is True:
            print(cr)
        
def optimize_timesteps(features, time_steps, feature_list, dataset, interval, labels, printall=False, printmax=False):
    """
    For now just return macro-avg f1 score, will add functionality where it will return what the user specifies
    """
    crs = {}
    for i in tqdm(range(interval, 0, -1)):
        bound = i / interval
        if printall is True:
            _, cr_dic = single_fit(features, time_steps, feature_list, bound, dataset, labels)
        else:
            _, cr_dic = single_fit(features, time_steps, feature_list, bound, dataset, labels, display=False)
            
        macro_f1 = cr_dic['macro avg']['f1-score']
        crs[macro_f1] = bound
        
    return crs.get(max(crs))
    
"""
WHY AM I DIONG 1/ INTERVAL
THE MATH IS WRONG 
FIX THIS ASAP
FACE PALM MAN
"""