{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ecf35f-3ff5-4f19-acd1-f91af9377afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b657c0-8f82-4af0-8c3b-d4274ad7a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.dataset import *\n",
    "from core.dprocessing import *\n",
    "from core.optimizers import *\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fd02c22-4a2a-4871-a528-2f154bb7e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = 'D:/Data/hoffmanlab/featureselection/data/'\n",
    "ligands = ['CpG', 'FLA', 'FSL', 'LPS', 'P3K', 'PIC', 'R84', 'TNF']\n",
    "sheet_type = 'am'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f24d5df-0772-46f5-bca7-637bdcef3e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Data(load_dir, ligands, sheet_type, merge=True, numpy=False)\n",
    "labels = dataset.iloc[:, [984]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a11c3a3-fb28-4210-b0ce-f0be42f20433",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['integrals_pos', 'min_trough2peak', 'integrals', 'envelope', 'oscpower', 'fold_change', 'valley_amps']\n",
    "time_steps = [98, None, 98, 25, None, 98, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd0d7919-327d-4153-b5fd-d334ff67f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/minha/Research/hoffmanlab/featuresel/data/untuned_model_feature_importance.csv')\n",
    "feature_importance = df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864ff3b0-fb0d-40b3-a7ae-601ae0abba10",
   "metadata": {},
   "source": [
    "#### Training a model on all time series per feature for top 7 features\n",
    "* integrals_pos\n",
    "* min_trough2peak\n",
    "* integrals\n",
    "* envelope\n",
    "* oscpower\n",
    "* fold_change\n",
    "* valley_amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be9d94-1609-4b95-9bd2-469c7504bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['integrals_pos_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e260fa-69b2-4859-a77e-40fb16a5918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'integrals_pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd80ef3f-ca48-47ab-b638-908a887f861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(1, 99):\n",
    "    column = feature_name + '_' + str(i)\n",
    "    column = dataset[column]\n",
    "    df = pd.concat([df, column], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e940b8-4752-438c-b258-67dd91eb44e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in list of feature names, pass in number of time steps for that corresponding feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a280a-d37f-4935-8efa-05965654c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = process(features, time_steps, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac335e2-ceb5-4c73-aaff-737731d3023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51190f8d-9f8a-4949-afac-b662c29a0c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acff5d3-25b7-4897-9537-d634fcda97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.iloc[:, [984]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c2be88-3d78-4c5e-9738-d931b380b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = test2.to_numpy(), labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ded56-5289-47d9-967f-6859f0ff755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba45f1-4fd4-4c2a-a523-d1da913eb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9ed10c-323c-4f62-961f-e839a00d8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ead7e7-fb0d-4b18-80f3-bc18ec7870c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a5089-1e6a-43cf-8598-825dc360598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c7280-599d-4653-8d3a-6f80a72ee5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f0449-3d10-4f8d-80b5-dfad10018645",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "for y_pred, y_true in zip(pred, y_val):\n",
    "    if y_pred == y_true:\n",
    "        x += 1\n",
    "print(x / len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c1967-71a7-4dc3-80ac-845d3c323ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# almost same accuracy vs trained on all features (985), removed a lot of noise ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553812d0-fe59-4fb4-8c55-3ed2a5855b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_val, pred, target_names=ligands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d989c3-d4a3-4f68-9c52-235fb6857dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5598d03d-f1da-4d27-b06a-bc8794a84522",
   "metadata": {},
   "source": [
    "### given the entire array of the top features:\n",
    "* parameters:\n",
    "    * distinct features\n",
    "    * upper bound (search in the upper x% of the array) for time steps for THOSE features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1bce70-5c9b-42a0-a8fe-0c9142a9f636",
   "metadata": {},
   "source": [
    "### trying 25% of top features for now:\n",
    "* loop through all partitions and find the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707608e9-479f-4fb8-a6cb-84b868378eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = partition_features(features, time_steps, feature_importance, 0.25, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef8e9a-6811-4cc5-bedf-36fd7450f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c60f0c-ed71-44e7-a548-5459905d3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.to_numpy()\n",
    "# labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043dae7-a6a9-4717-a7e4-8728b07866b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbefcdea-8357-430d-b0d8-b9da28c9edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116f92e-43e6-4187-9f2c-5c13e630dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e804c-a859-4537-b013-2f166eeed112",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a777633-c3ec-4c45-b4a9-4091063df4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b8aba-d4f0-4e43-9278-6d07995f514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_val, pred, target_names=ligands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca781b4a-fe1a-45da-bb53-9e571de53ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c527d-0be3-458a-9bbe-26acfe1c8a5e",
   "metadata": {},
   "source": [
    "### features trained on top 25% of timesteps for top 7 features yields 63% accuracy, 1% lower than model trained on 985 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c6384-1b78-47ba-8cad-372cb6a8b9e9",
   "metadata": {},
   "source": [
    "### make function to loop thru multiple bounds (partitions), find most optimal split (# of time steps for each feature)\n",
    "* maybe try different partitions for each feature instead of partitioning then grabbing the time steps?\n",
    "    * ie: taking top 10% time steps for integrals, integrals_pos, etc rather than splitting dataset into top 10% then finding time steps\n",
    "* could also try developing some method of using quantitative values to decide which time steps to use (xgboost returns numeric values as weights for each feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "105d47b4-6f32-4d3e-b323-ef8fec63cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 10\n",
    "initial_bound = 0.5\n",
    "initial_bound_2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f8ea1c-9e6b-4389-b4a6-7c0c87b904bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:25:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:10<01:31, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.43      0.50      0.46       198\n",
      "         FLA       0.44      0.35      0.39       156\n",
      "         FSL       0.61      0.55      0.58       207\n",
      "         LPS       0.56      0.63      0.59       175\n",
      "         P3K       0.60      0.49      0.54       175\n",
      "         PIC       0.63      0.70      0.66       120\n",
      "         R84       0.81      0.86      0.84       264\n",
      "         TNF       0.63      0.62      0.62       143\n",
      "\n",
      "    accuracy                           0.60      1438\n",
      "   macro avg       0.59      0.59      0.59      1438\n",
      "weighted avg       0.60      0.60      0.60      1438\n",
      "\n",
      "[01:25:35] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:20<01:21, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.52      0.51       223\n",
      "         FLA       0.49      0.44      0.47       162\n",
      "         FSL       0.59      0.56      0.57       199\n",
      "         LPS       0.57      0.66      0.61       179\n",
      "         P3K       0.55      0.47      0.51       150\n",
      "         PIC       0.64      0.68      0.66       109\n",
      "         R84       0.77      0.82      0.79       239\n",
      "         TNF       0.68      0.61      0.64       177\n",
      "\n",
      "    accuracy                           0.60      1438\n",
      "   macro avg       0.60      0.60      0.59      1438\n",
      "weighted avg       0.60      0.60      0.60      1438\n",
      "\n",
      "[01:25:45] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:30<01:11, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.52      0.59      0.55       205\n",
      "         FLA       0.48      0.38      0.42       157\n",
      "         FSL       0.51      0.51      0.51       181\n",
      "         LPS       0.59      0.67      0.63       178\n",
      "         P3K       0.56      0.50      0.53       151\n",
      "         PIC       0.72      0.71      0.71       134\n",
      "         R84       0.82      0.81      0.81       275\n",
      "         TNF       0.73      0.76      0.74       157\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.62      0.61      0.61      1438\n",
      "weighted avg       0.63      0.63      0.63      1438\n",
      "\n",
      "[01:25:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:40<01:01, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.54      0.54      0.54       208\n",
      "         FLA       0.50      0.39      0.43       166\n",
      "         FSL       0.56      0.60      0.58       177\n",
      "         LPS       0.63      0.76      0.69       186\n",
      "         P3K       0.64      0.47      0.54       156\n",
      "         PIC       0.74      0.75      0.75       137\n",
      "         R84       0.79      0.85      0.82       247\n",
      "         TNF       0.65      0.65      0.65       161\n",
      "\n",
      "    accuracy                           0.64      1438\n",
      "   macro avg       0.63      0.63      0.63      1438\n",
      "weighted avg       0.63      0.64      0.63      1438\n",
      "\n",
      "[01:26:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:51<00:51, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.58      0.54       202\n",
      "         FLA       0.46      0.37      0.41       171\n",
      "         FSL       0.56      0.50      0.53       189\n",
      "         LPS       0.52      0.60      0.56       167\n",
      "         P3K       0.52      0.38      0.44       144\n",
      "         PIC       0.64      0.72      0.68       127\n",
      "         R84       0.80      0.82      0.81       283\n",
      "         TNF       0.64      0.70      0.67       155\n",
      "\n",
      "    accuracy                           0.60      1438\n",
      "   macro avg       0.58      0.58      0.58      1438\n",
      "weighted avg       0.59      0.60      0.59      1438\n",
      "\n",
      "[01:26:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:01<00:41, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.56      0.53       203\n",
      "         FLA       0.41      0.32      0.36       156\n",
      "         FSL       0.61      0.56      0.59       192\n",
      "         LPS       0.64      0.65      0.64       192\n",
      "         P3K       0.48      0.46      0.47       130\n",
      "         PIC       0.69      0.76      0.73       131\n",
      "         R84       0.85      0.83      0.84       286\n",
      "         TNF       0.59      0.68      0.63       148\n",
      "\n",
      "    accuracy                           0.62      1438\n",
      "   macro avg       0.60      0.60      0.60      1438\n",
      "weighted avg       0.62      0.62      0.62      1438\n",
      "\n",
      "[01:26:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:11<00:30, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.53      0.58      0.55       215\n",
      "         FLA       0.38      0.36      0.37       149\n",
      "         FSL       0.55      0.48      0.51       188\n",
      "         LPS       0.63      0.67      0.65       180\n",
      "         P3K       0.60      0.52      0.56       141\n",
      "         PIC       0.69      0.72      0.70       142\n",
      "         R84       0.79      0.86      0.83       269\n",
      "         TNF       0.72      0.68      0.70       154\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.61      0.61      0.61      1438\n",
      "weighted avg       0.62      0.63      0.62      1438\n",
      "\n",
      "[01:26:37] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:21<00:20, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.50      0.50       196\n",
      "         FLA       0.47      0.40      0.43       167\n",
      "         FSL       0.53      0.53      0.53       180\n",
      "         LPS       0.58      0.65      0.62       186\n",
      "         P3K       0.52      0.46      0.49       137\n",
      "         PIC       0.70      0.74      0.72       138\n",
      "         R84       0.84      0.85      0.84       258\n",
      "         TNF       0.70      0.74      0.72       176\n",
      "\n",
      "    accuracy                           0.62      1438\n",
      "   macro avg       0.61      0.61      0.61      1438\n",
      "weighted avg       0.62      0.62      0.62      1438\n",
      "\n",
      "[01:26:47] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:32<00:10, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.52      0.50      0.51       213\n",
      "         FLA       0.35      0.32      0.33       146\n",
      "         FSL       0.55      0.56      0.55       186\n",
      "         LPS       0.54      0.60      0.57       172\n",
      "         P3K       0.50      0.44      0.47       144\n",
      "         PIC       0.66      0.65      0.66       150\n",
      "         R84       0.80      0.86      0.83       259\n",
      "         TNF       0.70      0.70      0.70       168\n",
      "\n",
      "    accuracy                           0.60      1438\n",
      "   macro avg       0.58      0.58      0.58      1438\n",
      "weighted avg       0.59      0.60      0.60      1438\n",
      "\n",
      "[01:26:57] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:42<00:00, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.52      0.58      0.55       210\n",
      "         FLA       0.46      0.37      0.41       164\n",
      "         FSL       0.54      0.51      0.53       181\n",
      "         LPS       0.56      0.62      0.59       172\n",
      "         P3K       0.59      0.46      0.52       156\n",
      "         PIC       0.68      0.71      0.70       131\n",
      "         R84       0.79      0.89      0.84       263\n",
      "         TNF       0.71      0.68      0.69       161\n",
      "\n",
      "    accuracy                           0.62      1438\n",
      "   macro avg       0.61      0.60      0.60      1438\n",
      "weighted avg       0.61      0.62      0.61      1438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimize_features(features, time_steps, feature_importance, dataset, initial_bound, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f3cc13f-7041-4613-a180-91aaa1e7b900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:27:08] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:16<02:24, 16.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.57      0.53       191\n",
      "         FLA       0.54      0.43      0.48       152\n",
      "         FSL       0.55      0.47      0.50       173\n",
      "         LPS       0.57      0.66      0.61       183\n",
      "         P3K       0.55      0.54      0.54       139\n",
      "         PIC       0.79      0.78      0.78       169\n",
      "         R84       0.81      0.85      0.83       278\n",
      "         TNF       0.68      0.65      0.67       153\n",
      "\n",
      "    accuracy                           0.64      1438\n",
      "   macro avg       0.62      0.62      0.62      1438\n",
      "weighted avg       0.64      0.64      0.64      1438\n",
      "\n",
      "[01:27:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:32<02:08, 16.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.51      0.54      0.53       205\n",
      "         FLA       0.49      0.41      0.44       157\n",
      "         FSL       0.61      0.56      0.59       193\n",
      "         LPS       0.57      0.61      0.59       183\n",
      "         P3K       0.52      0.47      0.49       144\n",
      "         PIC       0.68      0.73      0.71       138\n",
      "         R84       0.81      0.86      0.83       276\n",
      "         TNF       0.62      0.65      0.63       142\n",
      "\n",
      "    accuracy                           0.62      1438\n",
      "   macro avg       0.60      0.60      0.60      1438\n",
      "weighted avg       0.62      0.62      0.62      1438\n",
      "\n",
      "[01:27:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:48<01:52, 16.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.54      0.59      0.56       211\n",
      "         FLA       0.51      0.44      0.47       153\n",
      "         FSL       0.53      0.53      0.53       190\n",
      "         LPS       0.67      0.66      0.66       186\n",
      "         P3K       0.54      0.45      0.49       156\n",
      "         PIC       0.77      0.76      0.76       135\n",
      "         R84       0.77      0.87      0.82       234\n",
      "         TNF       0.65      0.66      0.65       173\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.62      0.62      0.62      1438\n",
      "weighted avg       0.62      0.63      0.62      1438\n",
      "\n",
      "[01:27:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:03<01:35, 15.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.47      0.56      0.51       198\n",
      "         FLA       0.42      0.39      0.40       135\n",
      "         FSL       0.61      0.50      0.55       191\n",
      "         LPS       0.62      0.69      0.65       172\n",
      "         P3K       0.59      0.50      0.54       161\n",
      "         PIC       0.75      0.74      0.74       144\n",
      "         R84       0.81      0.86      0.84       272\n",
      "         TNF       0.69      0.67      0.68       165\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.62      0.61      0.61      1438\n",
      "weighted avg       0.63      0.63      0.63      1438\n",
      "\n",
      "[01:28:12] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:19<01:19, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.51      0.55      0.53       198\n",
      "         FLA       0.46      0.45      0.46       139\n",
      "         FSL       0.54      0.50      0.52       204\n",
      "         LPS       0.61      0.67      0.64       166\n",
      "         P3K       0.54      0.48      0.51       157\n",
      "         PIC       0.76      0.70      0.73       124\n",
      "         R84       0.80      0.88      0.84       284\n",
      "         TNF       0.70      0.63      0.67       166\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.62      0.61      0.61      1438\n",
      "weighted avg       0.63      0.63      0.63      1438\n",
      "\n",
      "[01:28:28] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:35<01:03, 15.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.49      0.57      0.53       197\n",
      "         FLA       0.48      0.40      0.43       159\n",
      "         FSL       0.55      0.53      0.54       199\n",
      "         LPS       0.58      0.66      0.62       173\n",
      "         P3K       0.55      0.44      0.49       142\n",
      "         PIC       0.74      0.74      0.74       140\n",
      "         R84       0.80      0.87      0.83       261\n",
      "         TNF       0.69      0.64      0.67       167\n",
      "\n",
      "    accuracy                           0.62      1438\n",
      "   macro avg       0.61      0.60      0.61      1438\n",
      "weighted avg       0.62      0.62      0.62      1438\n",
      "\n",
      "[01:28:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:51<00:47, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.59      0.54       168\n",
      "         FLA       0.54      0.42      0.47       172\n",
      "         FSL       0.59      0.53      0.56       210\n",
      "         LPS       0.62      0.70      0.66       166\n",
      "         P3K       0.59      0.55      0.57       157\n",
      "         PIC       0.77      0.74      0.76       140\n",
      "         R84       0.82      0.86      0.83       269\n",
      "         TNF       0.65      0.69      0.67       156\n",
      "\n",
      "    accuracy                           0.65      1438\n",
      "   macro avg       0.63      0.64      0.63      1438\n",
      "weighted avg       0.64      0.65      0.64      1438\n",
      "\n",
      "[01:29:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [02:07<00:31, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.48      0.58      0.53       191\n",
      "         FLA       0.53      0.45      0.49       147\n",
      "         FSL       0.62      0.59      0.61       199\n",
      "         LPS       0.55      0.65      0.60       178\n",
      "         P3K       0.56      0.40      0.47       163\n",
      "         PIC       0.74      0.77      0.76       141\n",
      "         R84       0.85      0.84      0.85       251\n",
      "         TNF       0.67      0.70      0.69       168\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.63      0.62      0.62      1438\n",
      "weighted avg       0.64      0.63      0.63      1438\n",
      "\n",
      "[01:29:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [02:23<00:15, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.51      0.57      0.54       204\n",
      "         FLA       0.51      0.42      0.46       165\n",
      "         FSL       0.59      0.50      0.54       197\n",
      "         LPS       0.63      0.72      0.67       174\n",
      "         P3K       0.54      0.53      0.54       149\n",
      "         PIC       0.79      0.76      0.78       136\n",
      "         R84       0.85      0.84      0.84       259\n",
      "         TNF       0.63      0.70      0.66       154\n",
      "\n",
      "    accuracy                           0.64      1438\n",
      "   macro avg       0.63      0.63      0.63      1438\n",
      "weighted avg       0.64      0.64      0.64      1438\n",
      "\n",
      "[01:29:31] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:39<00:00, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.52      0.55      0.54       203\n",
      "         FLA       0.57      0.44      0.50       173\n",
      "         FSL       0.54      0.60      0.57       186\n",
      "         LPS       0.60      0.73      0.66       175\n",
      "         P3K       0.61      0.48      0.53       155\n",
      "         PIC       0.64      0.71      0.67       134\n",
      "         R84       0.85      0.84      0.84       257\n",
      "         TNF       0.66      0.64      0.65       155\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.62      0.62      0.62      1438\n",
      "weighted avg       0.63      0.63      0.63      1438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimize_features(features, time_steps, feature_importance, dataset, initial_bound_2, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b06dc3a-1f5a-4cbd-ab54-7daac1916fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_2 = feature_importance[:int(len(feature_importance) * 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa202c26-5913-46f7-adef-868d1b22a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.to_numpy()\n",
    "labels = labels.reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a97fa-e2e4-4750-ac7e-f96c68ec94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = []\n",
    "trains = []\n",
    "for i in range(10, 0, -1):\n",
    "    split = 1/i\n",
    "    pfl = feature_importance_2[:int(len(feature_importance_2) * split)]\n",
    "    data = partition_features(features, time_steps, pfl, 1, dataset)\n",
    "    data = data.to_numpy()\n",
    "    xx.append(data)\n",
    "    model = xgb.XGBClassifier(user_label_encoder=False)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.1)\n",
    "    trains.append(X_train)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_val)\n",
    "    kek = classification_report(y_val, pred, target_names=ligands)\n",
    "    print(kek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2e28fb-bb03-4c22-be99-22297f2d9419",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx[1].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab2ae49-045c-4c5e-bc81-8eeb7df4d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/minha/Research/hoffmanlab/featuresel/data/untuned_model_feature_importance.csv')\n",
    "untuned = df.values.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
