{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ecf35f-3ff5-4f19-acd1-f91af9377afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b657c0-8f82-4af0-8c3b-d4274ad7a861",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\Research\\hoffmanlab\\featuresel\\notebooks\\..\\core\\dataset.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mData\u001b[39m(load_dir, names, sheet, merge\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      5\u001b[0m     data \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "from core.dataset import *\n",
    "from core.dprocessing import *\n",
    "from core.optimizers import *\n",
    "from core.utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fd02c22-4a2a-4871-a528-2f154bb7e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = 'D:/Data/hoffmanlab/featureselection/data/'\n",
    "ligands = ['CpG', 'FLA', 'FSL', 'LPS', 'P3K', 'PIC', 'R84', 'TNF']\n",
    "sheet_type = 'am'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f24d5df-0772-46f5-bca7-637bdcef3e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Data(load_dir, ligands, sheet_type, merge=True, numpy=False)\n",
    "labels = dataset.iloc[:, [984]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a11c3a3-fb28-4210-b0ce-f0be42f20433",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['integrals_pos', 'min_trough2peak', 'integrals', 'envelope', 'oscpower', 'fold_change', 'valley_amps']\n",
    "time_steps = [98, None, 98, 25, None, 98, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd0d7919-327d-4153-b5fd-d334ff67f7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/minha/Research/hoffmanlab/featuresel/data/untuned_model_feature_importance.csv')\n",
    "feature_importance = df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864ff3b0-fb0d-40b3-a7ae-601ae0abba10",
   "metadata": {},
   "source": [
    "#### Training a model on all time series per feature for top 7 features\n",
    "* integrals_pos\n",
    "* min_trough2peak\n",
    "* integrals\n",
    "* envelope\n",
    "* oscpower\n",
    "* fold_change\n",
    "* valley_amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be9d94-1609-4b95-9bd2-469c7504bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['integrals_pos_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e260fa-69b2-4859-a77e-40fb16a5918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'integrals_pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd80ef3f-ca48-47ab-b638-908a887f861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in range(1, 99):\n",
    "    column = feature_name + '_' + str(i)\n",
    "    column = dataset[column]\n",
    "    df = pd.concat([df, column], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e940b8-4752-438c-b258-67dd91eb44e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in list of feature names, pass in number of time steps for that corresponding feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f70a280a-d37f-4935-8efa-05965654c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = process_features(features, time_steps, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51190f8d-9f8a-4949-afac-b662c29a0c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9acff5d3-25b7-4897-9537-d634fcda97c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dataset.iloc[:, [984]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3c2be88-3d78-4c5e-9738-d931b380b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = test2.to_numpy(), labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "889ded56-5289-47d9-967f-6859f0ff755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98ba45f1-4fd4-4c2a-a523-d1da913eb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9ed10c-323c-4f62-961f-e839a00d8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ead7e7-fb0d-4b18-80f3-bc18ec7870c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89a5089-1e6a-43cf-8598-825dc360598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c7280-599d-4653-8d3a-6f80a72ee5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f0449-3d10-4f8d-80b5-dfad10018645",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "for y_pred, y_true in zip(pred, y_val):\n",
    "    if y_pred == y_true:\n",
    "        x += 1\n",
    "print(x / len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c1967-71a7-4dc3-80ac-845d3c323ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# almost same accuracy vs trained on all features (985), removed a lot of noise ig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553812d0-fe59-4fb4-8c55-3ed2a5855b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_val, pred, target_names=ligands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d989c3-d4a3-4f68-9c52-235fb6857dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5598d03d-f1da-4d27-b06a-bc8794a84522",
   "metadata": {},
   "source": [
    "### given the entire array of the top features:\n",
    "* parameters:\n",
    "    * distinct features\n",
    "    * upper bound (search in the upper x% of the array) for time steps for THOSE features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1bce70-5c9b-42a0-a8fe-0c9142a9f636",
   "metadata": {},
   "source": [
    "### trying 25% of top features for now:\n",
    "* loop through all partitions and find the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707608e9-479f-4fb8-a6cb-84b868378eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = partition_features(features, time_steps, feature_importance, 0.25, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef8e9a-6811-4cc5-bedf-36fd7450f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c60f0c-ed71-44e7-a548-5459905d3ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.to_numpy()\n",
    "# labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043dae7-a6a9-4717-a7e4-8728b07866b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.reshape((-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbefcdea-8357-430d-b0d8-b9da28c9edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116f92e-43e6-4187-9f2c-5c13e630dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e804c-a859-4537-b013-2f166eeed112",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a777633-c3ec-4c45-b4a9-4091063df4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b8aba-d4f0-4e43-9278-6d07995f514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_val, pred, target_names=ligands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca781b4a-fe1a-45da-bb53-9e571de53ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198c527d-0be3-458a-9bbe-26acfe1c8a5e",
   "metadata": {},
   "source": [
    "### features trained on top 25% of timesteps for top 7 features yields 63% accuracy, 1% lower than model trained on 985 features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c6384-1b78-47ba-8cad-372cb6a8b9e9",
   "metadata": {},
   "source": [
    "### make function to loop thru multiple bounds (partitions), find most optimal split (# of time steps for each feature)\n",
    "* maybe try different partitions for each feature instead of partitioning then grabbing the time steps?\n",
    "    * ie: taking top 10% time steps for integrals, integrals_pos, etc rather than splitting dataset into top 10% then finding time steps\n",
    "* could also try developing some method of using quantitative values to decide which time steps to use (xgboost returns numeric values as weights for each feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "105d47b4-6f32-4d3e-b323-ef8fec63cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 10\n",
    "initial_bound = 0.5\n",
    "initial_bound_2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f8ea1c-9e6b-4389-b4a6-7c0c87b904bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:25:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:10<01:31, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.43      0.50      0.46       198\n",
      "         FLA       0.44      0.35      0.39       156\n",
      "         FSL       0.61      0.55      0.58       207\n",
      "         LPS       0.56      0.63      0.59       175\n",
      "         P3K       0.60      0.49      0.54       175\n",
      "         PIC       0.63      0.70      0.66       120\n",
      "         R84       0.81      0.86      0.84       264\n",
      "         TNF       0.63      0.62      0.62       143\n",
      "\n",
      "    accuracy                           0.60      1438\n",
      "   macro avg       0.59      0.59      0.59      1438\n",
      "weighted avg       0.60      0.60      0.60      1438\n",
      "\n",
      "[01:25:35] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:20<01:21, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.52      0.51       223\n",
      "         FLA       0.49      0.44      0.47       162\n",
      "         FSL       0.59      0.56      0.57       199\n",
      "         LPS       0.57      0.66      0.61       179\n",
      "         P3K       0.55      0.47      0.51       150\n",
      "         PIC       0.64      0.68      0.66       109\n",
      "         R84       0.77      0.82      0.79       239\n",
      "         TNF       0.68      0.61      0.64       177\n",
      "\n",
      "    accuracy                           0.60      1438\n",
      "   macro avg       0.60      0.60      0.59      1438\n",
      "weighted avg       0.60      0.60      0.60      1438\n",
      "\n",
      "[01:25:45] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:30<01:11, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.52      0.59      0.55       205\n",
      "         FLA       0.48      0.38      0.42       157\n",
      "         FSL       0.51      0.51      0.51       181\n",
      "         LPS       0.59      0.67      0.63       178\n",
      "         P3K       0.56      0.50      0.53       151\n",
      "         PIC       0.72      0.71      0.71       134\n",
      "         R84       0.82      0.81      0.81       275\n",
      "         TNF       0.73      0.76      0.74       157\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.62      0.61      0.61      1438\n",
      "weighted avg       0.63      0.63      0.63      1438\n",
      "\n",
      "[01:25:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:40<01:01, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.54      0.54      0.54       208\n",
      "         FLA       0.50      0.39      0.43       166\n",
      "         FSL       0.56      0.60      0.58       177\n",
      "         LPS       0.63      0.76      0.69       186\n",
      "         P3K       0.64      0.47      0.54       156\n",
      "         PIC       0.74      0.75      0.75       137\n",
      "         R84       0.79      0.85      0.82       247\n",
      "         TNF       0.65      0.65      0.65       161\n",
      "\n",
      "    accuracy                           0.64      1438\n",
      "   macro avg       0.63      0.63      0.63      1438\n",
      "weighted avg       0.63      0.64      0.63      1438\n",
      "\n",
      "[01:26:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:51<00:51, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.58      0.54       202\n",
      "         FLA       0.46      0.37      0.41       171\n",
      "         FSL       0.56      0.50      0.53       189\n",
      "         LPS       0.52      0.60      0.56       167\n",
      "         P3K       0.52      0.38      0.44       144\n",
      "         PIC       0.64      0.72      0.68       127\n",
      "         R84       0.80      0.82      0.81       283\n",
      "         TNF       0.64      0.70      0.67       155\n",
      "\n",
      "    accuracy                           0.60      1438\n",
      "   macro avg       0.58      0.58      0.58      1438\n",
      "weighted avg       0.59      0.60      0.59      1438\n",
      "\n",
      "[01:26:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:01<00:41, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.56      0.53       203\n",
      "         FLA       0.41      0.32      0.36       156\n",
      "         FSL       0.61      0.56      0.59       192\n",
      "         LPS       0.64      0.65      0.64       192\n",
      "         P3K       0.48      0.46      0.47       130\n",
      "         PIC       0.69      0.76      0.73       131\n",
      "         R84       0.85      0.83      0.84       286\n",
      "         TNF       0.59      0.68      0.63       148\n",
      "\n",
      "    accuracy                           0.62      1438\n",
      "   macro avg       0.60      0.60      0.60      1438\n",
      "weighted avg       0.62      0.62      0.62      1438\n",
      "\n",
      "[01:26:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:11<00:30, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.53      0.58      0.55       215\n",
      "         FLA       0.38      0.36      0.37       149\n",
      "         FSL       0.55      0.48      0.51       188\n",
      "         LPS       0.63      0.67      0.65       180\n",
      "         P3K       0.60      0.52      0.56       141\n",
      "         PIC       0.69      0.72      0.70       142\n",
      "         R84       0.79      0.86      0.83       269\n",
      "         TNF       0.72      0.68      0.70       154\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.61      0.61      0.61      1438\n",
      "weighted avg       0.62      0.63      0.62      1438\n",
      "\n",
      "[01:26:37] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [01:21<00:20, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.50      0.50       196\n",
      "         FLA       0.47      0.40      0.43       167\n",
      "         FSL       0.53      0.53      0.53       180\n",
      "         LPS       0.58      0.65      0.62       186\n",
      "         P3K       0.52      0.46      0.49       137\n",
      "         PIC       0.70      0.74      0.72       138\n",
      "         R84       0.84      0.85      0.84       258\n",
      "         TNF       0.70      0.74      0.72       176\n",
      "\n",
      "    accuracy                           0.62      1438\n",
      "   macro avg       0.61      0.61      0.61      1438\n",
      "weighted avg       0.62      0.62      0.62      1438\n",
      "\n",
      "[01:26:47] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:32<00:10, 10.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.52      0.50      0.51       213\n",
      "         FLA       0.35      0.32      0.33       146\n",
      "         FSL       0.55      0.56      0.55       186\n",
      "         LPS       0.54      0.60      0.57       172\n",
      "         P3K       0.50      0.44      0.47       144\n",
      "         PIC       0.66      0.65      0.66       150\n",
      "         R84       0.80      0.86      0.83       259\n",
      "         TNF       0.70      0.70      0.70       168\n",
      "\n",
      "    accuracy                           0.60      1438\n",
      "   macro avg       0.58      0.58      0.58      1438\n",
      "weighted avg       0.59      0.60      0.60      1438\n",
      "\n",
      "[01:26:57] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:42<00:00, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.52      0.58      0.55       210\n",
      "         FLA       0.46      0.37      0.41       164\n",
      "         FSL       0.54      0.51      0.53       181\n",
      "         LPS       0.56      0.62      0.59       172\n",
      "         P3K       0.59      0.46      0.52       156\n",
      "         PIC       0.68      0.71      0.70       131\n",
      "         R84       0.79      0.89      0.84       263\n",
      "         TNF       0.71      0.68      0.69       161\n",
      "\n",
      "    accuracy                           0.62      1438\n",
      "   macro avg       0.61      0.60      0.60      1438\n",
      "weighted avg       0.61      0.62      0.61      1438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimize_features(features, time_steps, feature_importance, dataset, initial_bound, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f3cc13f-7041-4613-a180-91aaa1e7b900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:27:08] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▎                                                                          | 1/10 [00:16<02:24, 16.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.57      0.53       191\n",
      "         FLA       0.54      0.43      0.48       152\n",
      "         FSL       0.55      0.47      0.50       173\n",
      "         LPS       0.57      0.66      0.61       183\n",
      "         P3K       0.55      0.54      0.54       139\n",
      "         PIC       0.79      0.78      0.78       169\n",
      "         R84       0.81      0.85      0.83       278\n",
      "         TNF       0.68      0.65      0.67       153\n",
      "\n",
      "    accuracy                           0.64      1438\n",
      "   macro avg       0.62      0.62      0.62      1438\n",
      "weighted avg       0.64      0.64      0.64      1438\n",
      "\n",
      "[01:27:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:32<02:08, 16.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.51      0.54      0.53       205\n",
      "         FLA       0.49      0.41      0.44       157\n",
      "         FSL       0.61      0.56      0.59       193\n",
      "         LPS       0.57      0.61      0.59       183\n",
      "         P3K       0.52      0.47      0.49       144\n",
      "         PIC       0.68      0.73      0.71       138\n",
      "         R84       0.81      0.86      0.83       276\n",
      "         TNF       0.62      0.65      0.63       142\n",
      "\n",
      "    accuracy                           0.62      1438\n",
      "   macro avg       0.60      0.60      0.60      1438\n",
      "weighted avg       0.62      0.62      0.62      1438\n",
      "\n",
      "[01:27:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:48<01:52, 16.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.54      0.59      0.56       211\n",
      "         FLA       0.51      0.44      0.47       153\n",
      "         FSL       0.53      0.53      0.53       190\n",
      "         LPS       0.67      0.66      0.66       186\n",
      "         P3K       0.54      0.45      0.49       156\n",
      "         PIC       0.77      0.76      0.76       135\n",
      "         R84       0.77      0.87      0.82       234\n",
      "         TNF       0.65      0.66      0.65       173\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.62      0.62      0.62      1438\n",
      "weighted avg       0.62      0.63      0.62      1438\n",
      "\n",
      "[01:27:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 4/10 [01:03<01:35, 15.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.47      0.56      0.51       198\n",
      "         FLA       0.42      0.39      0.40       135\n",
      "         FSL       0.61      0.50      0.55       191\n",
      "         LPS       0.62      0.69      0.65       172\n",
      "         P3K       0.59      0.50      0.54       161\n",
      "         PIC       0.75      0.74      0.74       144\n",
      "         R84       0.81      0.86      0.84       272\n",
      "         TNF       0.69      0.67      0.68       165\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.62      0.61      0.61      1438\n",
      "weighted avg       0.63      0.63      0.63      1438\n",
      "\n",
      "[01:28:12] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [01:19<01:19, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.51      0.55      0.53       198\n",
      "         FLA       0.46      0.45      0.46       139\n",
      "         FSL       0.54      0.50      0.52       204\n",
      "         LPS       0.61      0.67      0.64       166\n",
      "         P3K       0.54      0.48      0.51       157\n",
      "         PIC       0.76      0.70      0.73       124\n",
      "         R84       0.80      0.88      0.84       284\n",
      "         TNF       0.70      0.63      0.67       166\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.62      0.61      0.61      1438\n",
      "weighted avg       0.63      0.63      0.63      1438\n",
      "\n",
      "[01:28:28] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [01:35<01:03, 15.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.49      0.57      0.53       197\n",
      "         FLA       0.48      0.40      0.43       159\n",
      "         FSL       0.55      0.53      0.54       199\n",
      "         LPS       0.58      0.66      0.62       173\n",
      "         P3K       0.55      0.44      0.49       142\n",
      "         PIC       0.74      0.74      0.74       140\n",
      "         R84       0.80      0.87      0.83       261\n",
      "         TNF       0.69      0.64      0.67       167\n",
      "\n",
      "    accuracy                           0.62      1438\n",
      "   macro avg       0.61      0.60      0.61      1438\n",
      "weighted avg       0.62      0.62      0.62      1438\n",
      "\n",
      "[01:28:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:51<00:47, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.59      0.54       168\n",
      "         FLA       0.54      0.42      0.47       172\n",
      "         FSL       0.59      0.53      0.56       210\n",
      "         LPS       0.62      0.70      0.66       166\n",
      "         P3K       0.59      0.55      0.57       157\n",
      "         PIC       0.77      0.74      0.76       140\n",
      "         R84       0.82      0.86      0.83       269\n",
      "         TNF       0.65      0.69      0.67       156\n",
      "\n",
      "    accuracy                           0.65      1438\n",
      "   macro avg       0.63      0.64      0.63      1438\n",
      "weighted avg       0.64      0.65      0.64      1438\n",
      "\n",
      "[01:29:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [02:07<00:31, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.48      0.58      0.53       191\n",
      "         FLA       0.53      0.45      0.49       147\n",
      "         FSL       0.62      0.59      0.61       199\n",
      "         LPS       0.55      0.65      0.60       178\n",
      "         P3K       0.56      0.40      0.47       163\n",
      "         PIC       0.74      0.77      0.76       141\n",
      "         R84       0.85      0.84      0.85       251\n",
      "         TNF       0.67      0.70      0.69       168\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.63      0.62      0.62      1438\n",
      "weighted avg       0.64      0.63      0.63      1438\n",
      "\n",
      "[01:29:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [02:23<00:15, 15.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.51      0.57      0.54       204\n",
      "         FLA       0.51      0.42      0.46       165\n",
      "         FSL       0.59      0.50      0.54       197\n",
      "         LPS       0.63      0.72      0.67       174\n",
      "         P3K       0.54      0.53      0.54       149\n",
      "         PIC       0.79      0.76      0.78       136\n",
      "         R84       0.85      0.84      0.84       259\n",
      "         TNF       0.63      0.70      0.66       154\n",
      "\n",
      "    accuracy                           0.64      1438\n",
      "   macro avg       0.63      0.63      0.63      1438\n",
      "weighted avg       0.64      0.64      0.64      1438\n",
      "\n",
      "[01:29:31] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [02:39<00:00, 15.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.52      0.55      0.54       203\n",
      "         FLA       0.57      0.44      0.50       173\n",
      "         FSL       0.54      0.60      0.57       186\n",
      "         LPS       0.60      0.73      0.66       175\n",
      "         P3K       0.61      0.48      0.53       155\n",
      "         PIC       0.64      0.71      0.67       134\n",
      "         R84       0.85      0.84      0.84       257\n",
      "         TNF       0.66      0.64      0.65       155\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.62      0.62      0.62      1438\n",
      "weighted avg       0.63      0.63      0.63      1438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "optimize_features(features, time_steps, feature_importance, dataset, initial_bound_2, interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679f8a75-a55c-4b1f-b546-4a7bdb4c4deb",
   "metadata": {},
   "source": [
    "### valley_amps actually should be replaced by time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b090fae-d5c3-4466-a6ba-1ae3ea5b7f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['integrals_pos', 'min_trough2peak', 'integrals', 'time_series', 'envelope', 'oscpower', 'fold_change']\n",
    "time_steps = [98, None, 98, 98, 25, None, 98, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82877025-2537-4cff-acfd-028af08d80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = partition_features(features, time_steps, feature_importance, 0.25, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3261aac1-0c13-45db-b38f-6827ad86195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy()\n",
    "labels = labels.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c31e21a-bc0b-48ab-bf06-99c000bce992",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25c5a562-de49-48be-af83-3d88f5c6392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc96b957-c511-42f8-b329-8a84a8a9ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = xgb.XGBClassifier(use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c69141a-ffb5-489d-8d76-6f5ccffe1696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acff056b-3084-4d70-b110-09b59104c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = new_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8556bb3-b254-4455-8eb9-97fded216d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_val, pred, target_names=ligands, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "16644800-c0db-4015-b4de-e2a1470c8a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cr['macro avg']['f1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90b39dc2-003c-4786-81b8-d4bf6c6c29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77603bc4-5989-41a3-b976-e29a371c78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[x] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0807ae96-07a1-48fa-abbb-9ec20f18957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d[1] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8131772-8810-4768-b0de-0d7a6e9f788f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print(d.get(max(d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c55429-96d0-4d79-8d55-43a4ef8045fa",
   "metadata": {},
   "source": [
    "### replacing valley_amps with time_series doesn't make much of a difference\n",
    "* certain features seem to improve classification of certain ligands\n",
    "    * replacing valley_amps with time_series improves TNF but worsens almost everything else"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa49f7d-d472-4b4d-853a-058d5e67dd34",
   "metadata": {},
   "source": [
    "### try fitting models on only time_series data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2670a9ef-ed42-4079-a404-1f362d3654a8",
   "metadata": {},
   "source": [
    "### notes:\n",
    "* features1/timestep1 : vector of 7 time-series only features\n",
    "* features2/timestep2 : vector of 6 time-series only features\n",
    "* features3/timestep3 : features2/timestep2 + min_trough2peak\n",
    "* features4/timestep4 : top 7 features in feature importance\n",
    "* features5/timestep5 : features1/timestep1 + min_trough2peak\n",
    "* features6/timestep6 : features1/timestep1 + min_trough2peak + oscpower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64334261-8b6b-4f08-b53a-72f230294cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features1 = ['integrals_pos', 'integrals', 'time_series', 'envelope', 'fold_change', 'valley_amps', 'derivatives']\n",
    "timestep1 = [98, 98, 98, 25, 98, 15, 96] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcd31c5f-691b-4f88-891d-c4d2430e5d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features2 = ['integrals_pos', 'integrals', 'time_series', 'envelope', 'fold_change', 'valley_amps']\n",
    "timestep2 = [98, 98, 98, 25, 98, 15] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f306c882-7543-4fe8-962d-72c6ec1c55ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "features3 = ['integrals_pos', 'integrals', 'time_series', 'envelope', 'fold_change', 'valley_amps', 'min_trough2peak']\n",
    "timestep3 = [98, 98, 98, 25, 98, 15, None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e0b3a1c-7a87-48db-a8c4-6de6a9dc7c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "features4 = ['integrals_pos', 'min_trough2peak', 'integrals', 'time_series', 'envelope', 'oscpower', 'fold_change']\n",
    "timestep4 = [98, None, 98, 98, 25, None, 98, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e9cefb2-77f0-44c0-a325-d9778bf26f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features5 = ['integrals_pos', 'integrals', 'time_series', 'envelope', 'fold_change', 'valley_amps', 'derivatives', 'min_trough2peak']\n",
    "timestep5 = [98, 98, 98, 25, 98, 15, 96, None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44ce340d-1c32-4a89-9263-3681e74386e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features6 = ['integrals_pos', 'integrals', 'time_series', 'envelope', 'fold_change', 'valley_amps', 'derivatives', 'min_trough2peak', 'oscpower']\n",
    "timestep6 = [98, 98, 98, 25, 98, 15, 96, None, None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c4f68f-d8f6-4dfe-9606-64903cb7729f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:35] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.57      0.53       196\n",
      "         FLA       0.52      0.48      0.50       143\n",
      "         FSL       0.60      0.62      0.61       189\n",
      "         LPS       0.60      0.74      0.66       149\n",
      "         P3K       0.64      0.51      0.57       185\n",
      "         PIC       0.75      0.70      0.73       165\n",
      "         R84       0.80      0.82      0.81       249\n",
      "         TNF       0.73      0.67      0.70       162\n",
      "\n",
      "    accuracy                           0.65      1438\n",
      "   macro avg       0.64      0.64      0.64      1438\n",
      "weighted avg       0.65      0.65      0.65      1438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single_fit(features1, timestep1, feature_importance, 0.25, dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9410e82c-220a-4ae3-a480-602e5787df31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:49:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.48      0.56      0.52       196\n",
      "         FLA       0.51      0.44      0.47       143\n",
      "         FSL       0.57      0.57      0.57       189\n",
      "         LPS       0.58      0.77      0.66       149\n",
      "         P3K       0.64      0.51      0.57       185\n",
      "         PIC       0.77      0.67      0.72       165\n",
      "         R84       0.78      0.82      0.80       249\n",
      "         TNF       0.73      0.67      0.70       162\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.63      0.63      0.63      1438\n",
      "weighted avg       0.64      0.63      0.63      1438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single_fit(features2, timestep2, feature_importance, 0.25, dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a4afec6-25ce-4da4-8662-d6ebfc3dcc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:50:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.52      0.55      0.54       196\n",
      "         FLA       0.52      0.45      0.48       143\n",
      "         FSL       0.61      0.59      0.60       189\n",
      "         LPS       0.58      0.77      0.66       149\n",
      "         P3K       0.62      0.51      0.56       185\n",
      "         PIC       0.80      0.72      0.76       165\n",
      "         R84       0.76      0.85      0.80       249\n",
      "         TNF       0.74      0.68      0.71       162\n",
      "\n",
      "    accuracy                           0.65      1438\n",
      "   macro avg       0.64      0.64      0.64      1438\n",
      "weighted avg       0.65      0.65      0.65      1438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single_fit(features3, timestep3, feature_importance, 0.25, dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baba0f58-b878-423c-8ac3-4900a57661f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:52:31] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.45      0.54      0.49       196\n",
      "         FLA       0.49      0.46      0.48       143\n",
      "         FSL       0.56      0.57      0.56       189\n",
      "         LPS       0.57      0.73      0.64       149\n",
      "         P3K       0.61      0.46      0.52       185\n",
      "         PIC       0.78      0.70      0.74       165\n",
      "         R84       0.77      0.80      0.79       249\n",
      "         TNF       0.73      0.64      0.68       162\n",
      "\n",
      "    accuracy                           0.62      1438\n",
      "   macro avg       0.62      0.61      0.61      1438\n",
      "weighted avg       0.63      0.62      0.62      1438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single_fit(features4, timestep4, feature_importance, 0.25, dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59757ccb-8cd8-495c-a1ef-d87112c48b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:55:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.50      0.58      0.53       196\n",
      "         FLA       0.55      0.48      0.51       143\n",
      "         FSL       0.60      0.62      0.61       189\n",
      "         LPS       0.60      0.71      0.65       149\n",
      "         P3K       0.65      0.55      0.59       185\n",
      "         PIC       0.78      0.72      0.75       165\n",
      "         R84       0.79      0.83      0.81       249\n",
      "         TNF       0.73      0.65      0.69       162\n",
      "\n",
      "    accuracy                           0.65      1438\n",
      "   macro avg       0.65      0.64      0.64      1438\n",
      "weighted avg       0.66      0.65      0.65      1438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single_fit(features5, timestep5, feature_importance, 0.25, dataset, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9aec21ae-bc9f-486d-8d46-d4ed2f0e402c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:56:09] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.53      0.59      0.56       196\n",
      "         FLA       0.55      0.49      0.52       143\n",
      "         FSL       0.57      0.61      0.59       189\n",
      "         LPS       0.59      0.72      0.65       149\n",
      "         P3K       0.64      0.52      0.57       185\n",
      "         PIC       0.78      0.72      0.75       165\n",
      "         R84       0.77      0.83      0.80       249\n",
      "         TNF       0.76      0.64      0.70       162\n",
      "\n",
      "    accuracy                           0.65      1438\n",
      "   macro avg       0.65      0.64      0.64      1438\n",
      "weighted avg       0.65      0.65      0.65      1438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "single_fit(features6, timestep6, feature_importance, 0.25, dataset, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a8fc62-234d-443b-a72e-90b89f351aa5",
   "metadata": {},
   "source": [
    "### add in oscpower and mintrough2_peak to see if performance increases more?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471fe69d-1236-438b-8759-3d40fcc552bf",
   "metadata": {},
   "source": [
    "### so far:\n",
    "* changing bounds hardly affects performance, focus on actual feature selection instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13db920b-b5f6-4c17-ba2f-ccfe42227c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:35:55] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████▏                                                                         | 1/10 [02:03<18:27, 123.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.51      0.59      0.55       196\n",
      "         FLA       0.54      0.46      0.50       143\n",
      "         FSL       0.56      0.62      0.59       189\n",
      "         LPS       0.63      0.73      0.67       149\n",
      "         P3K       0.61      0.49      0.54       185\n",
      "         PIC       0.73      0.68      0.71       165\n",
      "         R84       0.80      0.82      0.81       249\n",
      "         TNF       0.73      0.67      0.70       162\n",
      "\n",
      "    accuracy                           0.64      1438\n",
      "   macro avg       0.64      0.63      0.63      1438\n",
      "weighted avg       0.65      0.64      0.64      1438\n",
      "\n",
      "[16:37:58] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▍                                                                 | 2/10 [04:02<16:07, 120.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.56      0.63      0.59       196\n",
      "         FLA       0.52      0.51      0.51       143\n",
      "         FSL       0.61      0.63      0.62       189\n",
      "         LPS       0.63      0.74      0.68       149\n",
      "         P3K       0.62      0.48      0.54       185\n",
      "         PIC       0.75      0.72      0.74       165\n",
      "         R84       0.81      0.84      0.82       249\n",
      "         TNF       0.74      0.68      0.71       162\n",
      "\n",
      "    accuracy                           0.66      1438\n",
      "   macro avg       0.66      0.65      0.65      1438\n",
      "weighted avg       0.66      0.66      0.66      1438\n",
      "\n",
      "[16:39:58] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▌                                                         | 3/10 [06:02<14:02, 120.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.54      0.61      0.57       196\n",
      "         FLA       0.53      0.49      0.51       143\n",
      "         FSL       0.60      0.66      0.63       189\n",
      "         LPS       0.62      0.72      0.67       149\n",
      "         P3K       0.65      0.53      0.58       185\n",
      "         PIC       0.76      0.72      0.74       165\n",
      "         R84       0.81      0.83      0.82       249\n",
      "         TNF       0.71      0.65      0.68       162\n",
      "\n",
      "    accuracy                           0.66      1438\n",
      "   macro avg       0.66      0.65      0.65      1438\n",
      "weighted avg       0.66      0.66      0.66      1438\n",
      "\n",
      "[16:41:58] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████████████████████▊                                                 | 4/10 [07:48<11:28, 114.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.53      0.63      0.58       196\n",
      "         FLA       0.51      0.46      0.49       143\n",
      "         FSL       0.59      0.61      0.60       189\n",
      "         LPS       0.62      0.72      0.67       149\n",
      "         P3K       0.65      0.52      0.58       185\n",
      "         PIC       0.79      0.69      0.74       165\n",
      "         R84       0.80      0.82      0.81       249\n",
      "         TNF       0.69      0.67      0.68       162\n",
      "\n",
      "    accuracy                           0.65      1438\n",
      "   macro avg       0.65      0.64      0.64      1438\n",
      "weighted avg       0.65      0.65      0.65      1438\n",
      "\n",
      "[16:43:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████                                         | 5/10 [09:20<08:52, 106.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.55      0.61      0.58       196\n",
      "         FLA       0.50      0.45      0.48       143\n",
      "         FSL       0.60      0.63      0.62       189\n",
      "         LPS       0.62      0.74      0.67       149\n",
      "         P3K       0.66      0.54      0.59       185\n",
      "         PIC       0.75      0.72      0.73       165\n",
      "         R84       0.81      0.83      0.82       249\n",
      "         TNF       0.73      0.66      0.69       162\n",
      "\n",
      "    accuracy                           0.66      1438\n",
      "   macro avg       0.65      0.65      0.65      1438\n",
      "weighted avg       0.66      0.66      0.66      1438\n",
      "\n",
      "[16:45:15] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 6/10 [10:39<06:29, 97.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.53      0.65      0.59       196\n",
      "         FLA       0.52      0.48      0.49       143\n",
      "         FSL       0.61      0.62      0.62       189\n",
      "         LPS       0.61      0.71      0.65       149\n",
      "         P3K       0.69      0.53      0.60       185\n",
      "         PIC       0.78      0.70      0.73       165\n",
      "         R84       0.79      0.83      0.81       249\n",
      "         TNF       0.74      0.65      0.69       162\n",
      "\n",
      "    accuracy                           0.66      1438\n",
      "   macro avg       0.66      0.65      0.65      1438\n",
      "weighted avg       0.66      0.66      0.66      1438\n",
      "\n",
      "[16:46:35] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [11:45<04:21, 87.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.53      0.61      0.56       196\n",
      "         FLA       0.53      0.50      0.51       143\n",
      "         FSL       0.58      0.60      0.59       189\n",
      "         LPS       0.64      0.72      0.68       149\n",
      "         P3K       0.67      0.54      0.60       185\n",
      "         PIC       0.77      0.73      0.75       165\n",
      "         R84       0.79      0.84      0.81       249\n",
      "         TNF       0.77      0.67      0.72       162\n",
      "\n",
      "    accuracy                           0.66      1438\n",
      "   macro avg       0.66      0.65      0.65      1438\n",
      "weighted avg       0.66      0.66      0.66      1438\n",
      "\n",
      "[16:47:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 8/10 [12:35<02:30, 75.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.51      0.61      0.55       196\n",
      "         FLA       0.51      0.46      0.48       143\n",
      "         FSL       0.60      0.63      0.62       189\n",
      "         LPS       0.59      0.70      0.64       149\n",
      "         P3K       0.66      0.54      0.60       185\n",
      "         PIC       0.78      0.72      0.75       165\n",
      "         R84       0.81      0.82      0.82       249\n",
      "         TNF       0.73      0.66      0.69       162\n",
      "\n",
      "    accuracy                           0.65      1438\n",
      "   macro avg       0.65      0.64      0.64      1438\n",
      "weighted avg       0.66      0.65      0.65      1438\n",
      "\n",
      "[16:48:30] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [13:12<01:03, 63.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.52      0.61      0.56       196\n",
      "         FLA       0.51      0.48      0.49       143\n",
      "         FSL       0.59      0.63      0.61       189\n",
      "         LPS       0.58      0.67      0.62       149\n",
      "         P3K       0.63      0.48      0.54       185\n",
      "         PIC       0.78      0.72      0.74       165\n",
      "         R84       0.79      0.84      0.81       249\n",
      "         TNF       0.77      0.67      0.72       162\n",
      "\n",
      "    accuracy                           0.65      1438\n",
      "   macro avg       0.65      0.64      0.64      1438\n",
      "weighted avg       0.65      0.65      0.65      1438\n",
      "\n",
      "[16:49:07] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [13:31<00:00, 81.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         CpG       0.48      0.55      0.52       196\n",
      "         FLA       0.48      0.44      0.46       143\n",
      "         FSL       0.57      0.61      0.59       189\n",
      "         LPS       0.55      0.68      0.61       149\n",
      "         P3K       0.63      0.50      0.56       185\n",
      "         PIC       0.80      0.69      0.74       165\n",
      "         R84       0.78      0.82      0.80       249\n",
      "         TNF       0.73      0.67      0.70       162\n",
      "\n",
      "    accuracy                           0.63      1438\n",
      "   macro avg       0.63      0.62      0.62      1438\n",
      "weighted avg       0.64      0.63      0.63      1438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d = optimize_timesteps(features1, timestep1, feature_importance, dataset, 10, labels, printall=True, printmax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c697cbaa-3fd5-42a6-bcca-b717255da34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cc72d3-8339-403e-9368-22e881a91d20",
   "metadata": {},
   "source": [
    "### 0.4 is the optimal bound for splitting the time steps (for now at least0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b1a7586-bceb-42c7-867d-04837891a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpumodel = xgb.XGBClassifier(tree_method='gpu_hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39bc3873-3cc6-450b-9238-be369338d636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minha\\miniconda3\\envs\\peep\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[19:05:42] c:\\ci\\xgboost-split_1638290375667\\work\\src\\common\\common.h:157: XGBoost version not compiled with GPU support.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgpumodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\peep\\lib\\site-packages\\xgboost\\core.py:506\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    505\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\peep\\lib\\site-packages\\xgboost\\sklearn.py:1250\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1230\u001b[0m model, feval, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, eval_metric, params)\n\u001b[0;32m   1231\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1232\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1233\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     label_transform\u001b[38;5;241m=\u001b[39mlabel_transform,\n\u001b[0;32m   1248\u001b[0m )\n\u001b[1;32m-> 1250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\peep\\lib\\site-packages\\xgboost\\training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\peep\\lib\\site-packages\\xgboost\\training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\peep\\lib\\site-packages\\xgboost\\core.py:1680\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1680\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1681\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1682\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1684\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\peep\\lib\\site-packages\\xgboost\\core.py:218\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [19:05:42] c:\\ci\\xgboost-split_1638290375667\\work\\src\\common\\common.h:157: XGBoost version not compiled with GPU support."
     ]
    }
   ],
   "source": [
    "gpumodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087abfdc-9037-456a-b4cb-96c4d99c597f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
