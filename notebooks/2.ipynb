{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9300309-dd8b-4589-9ce8-438f851a30d6",
   "metadata": {},
   "source": [
    "### comparing xgboost model with 7 features vs all 985 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03e323d-8e4d-4a09-9eb4-fa2269c302e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04cff4f1-5d6e-4a4a-982a-9ff0515ac181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.dataset import *\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a381774f-bb5a-4d7b-9093-503164a80d54",
   "metadata": {},
   "source": [
    "#### identifying all feature columns corresponding to 7 selected features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d30e28-c80c-4e64-9647-467384e1231a",
   "metadata": {},
   "source": [
    "##### Previously: ~ 62% accuracy when trained with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a780835-ad3b-446f-be8f-276ebac351d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dir = 'D:/Data/hoffmanlab/featureselection/data/'\n",
    "ligands = ['CpG', 'FLA', 'FSL', 'LPS', 'P3K', 'PIC', 'R84', 'TNF']\n",
    "sheet_type = 'am'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1235a06b-69cf-4758-9d8a-ed411d8c4ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Data(load_dir, ligands, sheet_type, merge=True, numpy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ea75df-35a8-4b92-9a06-cd5a22e27928",
   "metadata": {},
   "source": [
    "##### Extract the 7 seven features from this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a26926f-0028-414e-b6c6-522ecadd464f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  'time_series_1',   'time_series_2',   'time_series_3',\n",
       "         'time_series_4',   'time_series_5',   'time_series_6',\n",
       "         'time_series_7',   'time_series_8',   'time_series_9',\n",
       "        'time_series_10',\n",
       "       ...\n",
       "        'fold_change_92',  'fold_change_93',  'fold_change_94',\n",
       "        'fold_change_95',  'fold_change_96',  'fold_change_97',\n",
       "        'fold_change_98', 'max_fold_change',       'max_value',\n",
       "                       0],\n",
       "      dtype='object', length=985)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbc32d3e-b7bc-4c95-af3e-22a1a13bc984",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = [dataset['integrals_pos_38'], dataset['min_trough2peak'], dataset['integrals_pos_11'], dataset['integrals_40'],\n",
    "                      dataset['integrals_pos_14'], dataset['time_series_2'], dataset['integrals_pos_12']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3930f75-2526-4817-8573-f9f23bd8b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c43c23d1-166d-4940-b0f0-d2f0d80b6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat(extracted_features, axis=1).to_numpy()\n",
    "labels = dataset.iloc[:, [984]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68cef903-bee2-4af9-85aa-ff00dc11e2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14376, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82b79649-0a98-46d0-a1f7-4428f1e64b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([data, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b48d2d8c-8448-4801-b71b-4dd5047e59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.reshape(labels, (-1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c59d5113-ddbf-4d75-af0f-46d2e6700ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14376, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0f48f9a-736b-42a4-9f1d-cf72793cf271",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd66c011-f003-4e6b-97e1-897b17046586",
   "metadata": {},
   "source": [
    "#### training the model on the top 7 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c108e2f2-5a92-4148-b3a4-5d96765f5ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61e1f12b-d66f-48a4-9816-9f50ef6fb185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\minha\\miniconda3\\envs\\peep\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:19:24] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5ded5ec-1bab-46ef-926a-0d4880664b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52edc0db-536f-4416-ab3d-04c91b58a643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 7, ..., 2, 0, 7])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edde6c09-400e-4468-bc51-b613bd28f01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.480528511821975\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "for i, j in zip(pred, y_val):\n",
    "    if i == j:\n",
    "        acc += 1\n",
    "print(f'Accuracy: {acc / len(y_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c65d1c5-2850-4a25-8971-e5b279cecaa1",
   "metadata": {},
   "source": [
    "#### Accuracy went from 62% -> 48% when trained on 7 features vs 985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adf108c6-d10a-4d96-8009-ff22d2ab7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ignore everything below this line for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2126caa-4a29-495c-97e6-99d8f493c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset.columns.get_loc('power_1'), dataset.columns.get_loc('power_125'))\n",
    "# power = dataset.iloc[:, [i for i in range(650, 775)]]\n",
    "# print(dataset.columns.get_loc('max_value'))\n",
    "# max_value = dataset.iloc[:, [983]]\n",
    "# print(dataset.columns.get_loc('ipt_1'), dataset.columns.get_loc('ipt_15'))\n",
    "# ipt = dataset.iloc[:, [i for i in range(449, 464)]]\n",
    "# print(dataset.columns.get_loc('num_peaks'))\n",
    "# num_peaks = dataset.iloc[:, [464]]\n",
    "# print(dataset.columns.get_loc('valley_amps_1'), )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57085196-67f3-4907-a2ee-2a018e8834b1",
   "metadata": {},
   "source": [
    "#### Training a model on all time series per feature for top 7 features\n",
    "* integrals_pos\n",
    "* min_trough2peak\n",
    "* integrals\n",
    "* envelope\n",
    "* oscpower\n",
    "* fold_change\n",
    "* valley_amps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4f31a3-d968-4554-a948-48323a90994b",
   "metadata": {},
   "source": [
    "## To do\n",
    "* hyperparameter tuning\n",
    "* try a simpler model, look at coefficients\n",
    "* look at correlation between features\n",
    "* take a subset of features...\n",
    "* use that correlation to identify redundant features, clean out the features used in the 'reduced-training' model\n",
    "* downsample random features, see what happens\n",
    "* visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd943b-63b4-46a6-b26a-d6bd69c284b9",
   "metadata": {},
   "source": [
    "## Figure out a way to remove redundant features or combine them\n",
    "* if the top feature is like integral 38, 37, 36\n",
    "* take maximum, average, ... etc?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e2d1a7-0fed-481c-a29e-b0c22450e71c",
   "metadata": {},
   "source": [
    "## Once we have xyz amount of features\n",
    "* visualizations: distance between all features vs standard matrix for selected features\n",
    "* dimensionality reduction\n",
    "* find foundation of xyz features, give or take a little and see what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69d7788-7647-4650-9884-73cf10a4a7a5",
   "metadata": {},
   "source": [
    "## Graphs\n",
    "* could partition the giant graph of feature importance into multiple little ones so you can actually see what's going on lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ebfa7-65e8-4248-8f5a-7848c85c7382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
